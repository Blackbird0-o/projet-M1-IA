{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Template.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "O4DCDqXN-gsq",
        "pxq8Xdhw-bNr",
        "sBXv4ImW_60C"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbUFxk5L-jE0",
        "colab_type": "text"
      },
      "source": [
        "# DRIVE MOUNT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNPthfD396hf",
        "colab_type": "code",
        "outputId": "c3cbc1bf-aec9-4066-c34c-fab6d6b4f6c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4DCDqXN-gsq",
        "colab_type": "text"
      },
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_d6cJdY-OPS",
        "colab_type": "code",
        "outputId": "d0b6dd8c-58ef-4551-f12c-a95e86c912c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Activation, Dense, Dropout, Flatten, BatchNormalization, CuDNNLSTM, LSTM, Conv1D,UpSampling1D, MaxPool1D,MaxPooling1D, Permute, Reshape\n",
        "from keras.optimizers import RMSprop, adam\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import pywt\n",
        "import pandas as pd\n",
        "from matplotlib import cm\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.base import BaseSampler\n",
        "from collections import Counter # counts the number of elements per class ({0: 5050, 1: 37})\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxq8Xdhw-bNr",
        "colab_type": "text"
      },
      "source": [
        "# DATA PROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPQseyW3-P4g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def RPN(x):\n",
        "    '''\n",
        "    Calcule la RPN d'un signal (Relative Power Noise)\n",
        "    input :\n",
        "        x = array numpy, le signal dont on souhaite calculer la RPN\n",
        "        \n",
        "    output :\n",
        "        x_RPN = array numpy, la RPN du signal\n",
        "        '''\n",
        "    mean = np.mean(x,axis=1).reshape(x.shape[0],1)\n",
        "    return (x-mean)/mean\n",
        "  \n",
        "def shuffle(x,y):\n",
        "    # shuffle\n",
        "    index = np.arange(y.shape[0])\n",
        "    np.random.shuffle(index)\n",
        "    x = x[index]\n",
        "    y = y[index]\n",
        "    \n",
        "    return x,y\n",
        "    \n",
        "def bootstrap(x_train,y_train,inv=True) :\n",
        "    if inv :\n",
        "      x_train,y_train = inv_data(x_train,y_train)\n",
        "      \n",
        "    x_train1 = x_train[np.where(y_train == 1)[0]] #Separation du train_set selon le label\n",
        "    x_train0 = x_train[np.where(y_train == 0)[0]]\n",
        "    index_train = np.random.randint(0,x_train1.shape[0] , size=x_train0.shape[0]) #genere une liste d'index \n",
        "                                                                                  #aléatoire pour equilibrer les données\n",
        "    x_train_1_boot = x_train1[index_train]\n",
        "    y_train_boot = np.concatenate((np.ones(x_train0.shape[0]),np.zeros(x_train0.shape[0]))) #on génère une liste de labels avec autant de 1 que de 0\n",
        "    x_train_boot = np.concatenate((x_train_1_boot,x_train0)) #on rassemble les données une fois équilibrées\n",
        "    \n",
        "    x_train_boot,y_train_boot  = shuffle(x_train_boot,y_train_boot)\n",
        "    \n",
        "    return x_train_boot,y_train_boot\n",
        "\n",
        "def dataload(path='data/',merge=True) :\n",
        "    # Loading datas\n",
        "    data_train = pd.read_csv(path+'exoTrain.csv')\n",
        "    data_test = pd.read_csv(path+'exoTest.csv')\n",
        "    \n",
        "    # transformation des label en array de 0 et 1\n",
        "    y_train = np.array(data_train[\"LABEL\"])-1\n",
        "    y_test = np.array(data_test['LABEL'])-1\n",
        "    \n",
        "    # on charge les features\n",
        "    x_train = np.array(data_train.drop('LABEL',axis=1))\n",
        "    x_test = np.array(data_test.drop('LABEL',axis=1))\n",
        "    \n",
        "    if merge :\n",
        "      data = np.concatenate((x_train,x_test))\n",
        "      y = np.concatenate((y_train,y_test))\n",
        "      data0 = data[np.where(y==0)[0]]\n",
        "      y0 = y[np.where(y==0)[0]]\n",
        "      data1 = data[np.where(y==1)[0]]\n",
        "      y1 = y[np.where(y==1)[0]]\n",
        "      \n",
        "      x_train0,x_test0,y_train0,y_test0 = train_test_split(data0,y0, test_size = 0.1)\n",
        "      x_train1,x_test1,y_train1,y_test1 = train_test_split(data1,y1, test_size = 0.1)\n",
        "      \n",
        "      x_train = np.concatenate((x_train0,x_train1))\n",
        "      y_train = np.concatenate((y_train0,y_train1))\n",
        "      x_test = np.concatenate((x_test0,x_test1))\n",
        "      y_test = np.concatenate((y_test0,y_test1))\n",
        "      \n",
        "      x_train,y_train = shuffle(x_train,y_train)\n",
        "      x_test,y_test = shuffle(x_test,y_test)\n",
        "    \n",
        "    return x_train,y_train,x_test,y_test\n",
        "\n",
        "def pcaPlot(X, y, descr= 'temporel',plot_samples = 500):\n",
        "  '''\n",
        "  Defines and 10 components PCA of the dataset X and plots the first 3\n",
        "  '''\n",
        "  pca = PCA(n_components=10)\n",
        "  x_PCA = pca.fit_transform(X)\n",
        "\n",
        "  # let's visualize the data in 3d\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(111, projection='3d')\n",
        "  ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
        "  ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
        "  ax.set_zlabel('Principal Component 3', fontsize = 15)\n",
        "  ax.set_title('ACP du signal ' + descr, fontsize = 20)\n",
        "  targets = [0,1]\n",
        "  colors = ['b', 'r']\n",
        "  x_PCA_plot = x_PCA[0:plot_samples]\n",
        "\n",
        "  for target, color in zip(targets,colors):\n",
        "      indexes = np.where(y[0:plot_samples] == target)\n",
        "      ax.scatter(x_PCA_plot[indexes,0]\n",
        "                , x_PCA_plot[indexes,1],\n",
        "                x_PCA_plot[indexes,2]\n",
        "                , c = color\n",
        "                , s = 50)\n",
        "  ax.legend(['pas d\\'exoplanetes', 'exoplanetes'])\n",
        "  ax.grid()\n",
        "  plt.show()\n",
        "  return None\n",
        "\n",
        "#Make an identity sampler\n",
        "class FakeSampler(BaseSampler):\n",
        "\n",
        "    _sampling_type = 'bypass'\n",
        "\n",
        "    def _fit_resample(self, X, y):\n",
        "        return X, y\n",
        "\n",
        "def plot_resampling(X, y, sampling, ax):\n",
        "    X_res, y_res = sampling.fit_resample(X, y)\n",
        "    ax.scatter(X_res[:, 0], X_res[:, 1], c=y_res, alpha=0.8, edgecolor='k')\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.get_xaxis().tick_bottom()\n",
        "    ax.get_yaxis().tick_left()\n",
        "    ax.spines['left'].set_position(('outward', 10))\n",
        "    ax.spines['bottom'].set_position(('outward', 10))\n",
        "    return Counter(y_res)\n",
        "\n",
        "def SMOTE_plot(x_train, y_train):\n",
        "  sampler = FakeSampler()\n",
        "\n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 15))\n",
        "  plot_resampling(x_train, y_train, sampler, ax1)\n",
        "  ax1.set_title('Original data - y={}'.format(Counter(y_train)))\n",
        "\n",
        "  plot_resampling(x_train, y_train, SMOTE(random_state = 0), ax2)\n",
        "  ax2.set_title('Resampling using {}'.format(SMOTE(random_state=0).__class__.__name__))\n",
        "  fig.tight_layout()\n",
        "  plt.show()\n",
        "  return None\n",
        "\n",
        "def transform_dataset(X, mode='wavelet', wname='db5',nsamples=10):\n",
        "  if mode == 'wavelet':\n",
        "    return pywt.dwt(X, wname)[0][:,0:nsamples]\n",
        "\n",
        "  elif mode == 'fft':\n",
        "    return np.abs(np.fft.fft(X))[:,0:nsamples]\n",
        "\n",
        "  elif mode == 'all_in':\n",
        "    allz = np.abs(np.fft.fft(X))[:,0:nsamples]\n",
        "    wnames = ['db5','sym5','coif5','bior2.4']\n",
        "    for wn in wnames:\n",
        "      np.append(allz, pywt.dwt(X, wn)[0][:,0:nsamples], axis=1)\n",
        "    return allz\n",
        "\n",
        "def scale_datasets(X_train, X_test, param='standardScaling', reshape=True):\n",
        "  SC = StandardScaler()\n",
        "  train_shape = X_train.shape\n",
        "  test_shape = X_test.shape\n",
        "    \n",
        "  if param == 'standardScaling':\n",
        "    SC.fit(X_train)\n",
        "    if reshape:\n",
        "      return SC.transform(X_train).reshape(train_shape[0],train_shape[1],1), SC.transform(X_test).reshape(test_shape[0],test_shape[1],1)\n",
        "    else :\n",
        "      return SC.transform(X_train), SC.transform(X_test)\n",
        "\n",
        "  elif param == 'RPN':\n",
        "    \n",
        "    mean_train = np.mean(X_train,axis=1).reshape(X_train.shape[0],1)\n",
        "    mean_test = np.mean(X_test,axis=1).reshape(X_test.shape[0],1)\n",
        "    \n",
        "    norm_train = np.max(np.abs(X_train),axis=1).reshape(-1,1)#np.linalg.norm(X_train,axis=1).reshape(-1,1)\n",
        "    norm_test = np.max(np.abs(X_test),axis=1).reshape(-1,1)#np.linalg.norm(X_test,axis=1).reshape(-1,1)\n",
        "    \n",
        "    if reshape:\n",
        "      return ((X_train-mean_train)/norm_train) .reshape(train_shape[0],train_shape[1],1) , ((X_test-mean_test)/norm_test) .reshape(test_shape[0],test_shape[1],1)\n",
        "    else :\n",
        "      return ((X_train-mean_train)/norm_train)  , ((X_test-mean_test)/norm_test) \n",
        "    \n",
        "    \n",
        "  elif param == 'transpose':\n",
        "    X_train = np.transpose(X_train)\n",
        "    if train_shape != test_shape :\n",
        "      X_test = np.tile(X_test,(10,1))[0:train_shape[0]]\n",
        "    X_test = np.transpose(X_test)\n",
        "    SC.fit(X_train)\n",
        "    if reshape:\n",
        "      return np.transpose(SC.transform(X_train)).reshape(train_shape[0],train_shape[1],1), np.transpose(SC.transform(X_test))[0:test_shape[0]].reshape(test_shape[0],test_shape[1],1)\n",
        "    else :\n",
        "      return np.transpose(SC.transform(X_train)), np.transpose(SC.transform(X_test))[0:test_shape[0]]\n",
        "    \n",
        "  elif param == 'flatten':\n",
        "    X_train = X_train.flatten().reshape((-1,1))\n",
        "    X_test = X_test.flatten().reshape((-1,1))\n",
        "    SC.fit(X_train)\n",
        "    if reshape:\n",
        "      return SC.transform(X_train).reshape(train_shape[0],train_shape[1],1), SC.transform(X_test).reshape(test_shape[0],test_shape[1],1)\n",
        "    else :\n",
        "      return SC.transform(X_train).reshape(train_shape[0],train_shape[1]), SC.transform(X_test).reshape(test_shape[0],test_shape[1])\n",
        "  \n",
        "  elif param == 'norm':\n",
        "    norm_train = np.linalg.norm(X_train,axis=1).reshape(-1,1)\n",
        "    norm_test = np.linalg.norm(X_test,axis=1).reshape(-1,1)\n",
        "    if reshape:\n",
        "      return (X_train/norm_train).reshape(train_shape[0],train_shape[1],1), (X_test/norm_test).reshape(test_shape[0],test_shape[1],1)\n",
        "    else :\n",
        "      return X_train/norm_train, X_test/norm_test\n",
        "    \n",
        "  elif param == 'norm_flatten':\n",
        "    norm_train = np.linalg.norm(X_train)\n",
        "    norm_test = np.linalg.norm(X_test,axis=1).reshape(-1,1)\n",
        "    if reshape:\n",
        "      return (X_train/norm_train).reshape(train_shape[0],train_shape[1],1), (X_test/norm_train).reshape(test_shape[0],test_shape[1],1)\n",
        "    else :\n",
        "      return X_train/norm_train, X_test/norm_train\n",
        "\n",
        "def inv_data(X, y):\n",
        "  X_flipped = np.flip(X[np.where(y == 1)[0]], 1)\n",
        "  y_flipped = np.ones((X_flipped.shape[0]))\n",
        "  return np.concatenate((X, X_flipped)), np.concatenate((y, y_flipped))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBXv4ImW_60C",
        "colab_type": "text"
      },
      "source": [
        "# METRICS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YALCfl9M_-KW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getScores(pred, result):\n",
        "  print('Precision :')\n",
        "  print(precision_score(result, pred))\n",
        "\n",
        "  print('Recall :')\n",
        "  print(recall_score(result, pred))\n",
        "\n",
        "  print('F1 Score :')\n",
        "  scoref1 = f1_score(result, pred)\n",
        "  print(scoref1)\n",
        "\n",
        "  print('MSE :')\n",
        "  modelError = mean_squared_error(result, pred)\n",
        "  print(modelError)\n",
        "\n",
        "  print('')\n",
        "  print('confusion_matrix : ')\n",
        "  confusion = confusion_matrix(result, pred)\n",
        "  print(confusion)\n",
        "  print('')\n",
        "  return scoref1, modelError, confusion\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "  \"\"\"Recall metric.\n",
        "  Only computes a batch-wise average of recall.\n",
        "  Computes the recall, a metric for multi-label classification of\n",
        "  how many relevant items are selected.\n",
        "  \"\"\"\n",
        "  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "  possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "  return true_positives / (possible_positives + K.epsilon())\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "  \"\"\"Precision metric.\n",
        "  Only computes a batch-wise average of precision.\n",
        "  Computes the precision, a metric for multi-label classification of\n",
        "  how many selected items are relevant.\n",
        "  \"\"\"\n",
        "  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "  predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "  return true_positives / (predicted_positives + K.epsilon())\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "  preci = precision(y_true, y_pred)\n",
        "  rec = recall(y_true, y_pred)\n",
        "  return 2*((preci*rec)/(preci+rec+K.epsilon()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl4HT84oAOgo",
        "colab_type": "text"
      },
      "source": [
        "# NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvmrkQthFIER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def myNN(X, y, X_tst, y_tst):\n",
        "  model = Sequential()\n",
        "\n",
        "  pred = model.predict(X_tst)\n",
        "\n",
        "  return model, pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ml5ft1czAcVD",
        "colab_type": "text"
      },
      "source": [
        "# TESTING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D83iTNYAAobP",
        "colab_type": "text"
      },
      "source": [
        "## Data load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hI6h7wmAeRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train, x_test, y_test = dataload(merge=True,path='drive/My Drive/M1/IA/')\n",
        "\n",
        "# création du vecteur temps (h)\n",
        "t = np.arange(len(x_train[0])) * (36.0/60.0)\n",
        "dt = 36 * 60  # sampling rate (s) les données sont prises avec 36min d'écart\n",
        "f = np.fft.fftfreq(x_train.shape[1], dt)  # vecteur fréquence en (Hz)\n",
        "\n",
        "x_train, y_train = bootstrap(x_train, y_train)\n",
        "x_test, y_test = bootstrap(x_test, y_test,inv=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha_DNHRlBzFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test = scale_datasets(x_train, x_test,param='RPN')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPokCbCXAyJg",
        "colab_type": "text"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1anG1r8sA0GR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train model\n",
        "model, pred = myNN(x_train,y_train,x_test,y_test)\n",
        "\n",
        "# Evaluate model\n",
        "getScores(y_test, pred)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}