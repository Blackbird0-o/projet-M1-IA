{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "F_Nbook_w/cross.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tl4HT84oAOgo",
        "D83iTNYAAobP"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbUFxk5L-jE0",
        "colab_type": "text"
      },
      "source": [
        "# DRIVE MOUNT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNPthfD396hf",
        "colab_type": "code",
        "outputId": "d4e42a7d-9750-4062-e95d-5c578e126cb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4DCDqXN-gsq",
        "colab_type": "text"
      },
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_d6cJdY-OPS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5e6ef848-23a2-4813-e211-526fcc0bfeda"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Activation, Dense, Dropout, Flatten, BatchNormalization, CuDNNLSTM, LSTM, Conv1D,UpSampling1D, MaxPool1D,MaxPooling1D, Permute, Reshape\n",
        "from keras.optimizers import RMSprop, adam\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import pywt\n",
        "import pandas as pd\n",
        "from matplotlib import cm\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.base import BaseSampler\n",
        "from collections import Counter # counts the number of elements per class ({0: 5050, 1: 37})\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxq8Xdhw-bNr",
        "colab_type": "text"
      },
      "source": [
        "# DATA PROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPQseyW3-P4g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def RPN(x):\n",
        "    '''\n",
        "    Calcule la RPN d'un signal (Relative Power Noise)\n",
        "    input :\n",
        "        x = array numpy, le signal dont on souhaite calculer la RPN\n",
        "        \n",
        "    output :\n",
        "        x_RPN = array numpy, la RPN du signal\n",
        "        '''\n",
        "    mean = np.mean(x,axis=1).reshape(x.shape[0],1)\n",
        "    return (x-mean)/mean\n",
        "  \n",
        "def shuffle(x,y):\n",
        "    # shuffle\n",
        "    index = np.arange(y.shape[0])\n",
        "    np.random.shuffle(index)\n",
        "    x = x[index]\n",
        "    y = y[index]\n",
        "    \n",
        "    return x,y\n",
        "    \n",
        "def bootstrap(x_train,y_train,inv=True) :\n",
        "    if inv :\n",
        "      x_train,y_train = inv_data(x_train,y_train)\n",
        "      \n",
        "    x_train1 = x_train[np.where(y_train == 1)[0]] #Separation du train_set selon le label\n",
        "    x_train0 = x_train[np.where(y_train == 0)[0]]\n",
        "    index_train = np.random.randint(0,x_train1.shape[0] , size=x_train0.shape[0]) #genere une liste d'index \n",
        "                                                                                  #aléatoire pour equilibrer les données\n",
        "    x_train_1_boot = x_train1[index_train]\n",
        "    y_train_boot = np.concatenate((np.ones(x_train0.shape[0]),np.zeros(x_train0.shape[0]))) #on génère une liste de labels avec autant de 1 que de 0\n",
        "    x_train_boot = np.concatenate((x_train_1_boot,x_train0)) #on rassemble les données une fois équilibrées\n",
        "    \n",
        "    x_train_boot,y_train_boot  = shuffle(x_train_boot,y_train_boot)\n",
        "    \n",
        "    return x_train_boot,y_train_boot\n",
        "\n",
        "def dataload(path='data/',merge=True) :\n",
        "    # Loading datas\n",
        "    data_train = pd.read_csv(path+'exoTrain.csv')\n",
        "    data_test = pd.read_csv(path+'exoTest.csv')\n",
        "    \n",
        "    # transformation des label en array de 0 et 1\n",
        "    y_train = np.array(data_train[\"LABEL\"])-1\n",
        "    y_test = np.array(data_test['LABEL'])-1\n",
        "    \n",
        "    # on charge les features\n",
        "    x_train = np.array(data_train.drop('LABEL',axis=1))\n",
        "    x_test = np.array(data_test.drop('LABEL',axis=1))\n",
        "    \n",
        "    if merge :\n",
        "      data = np.concatenate((x_train,x_test))\n",
        "      y = np.concatenate((y_train,y_test))\n",
        "      data0 = data[np.where(y==0)[0]]\n",
        "      y0 = y[np.where(y==0)[0]]\n",
        "      data1 = data[np.where(y==1)[0]]\n",
        "      y1 = y[np.where(y==1)[0]]\n",
        "      \n",
        "      x_train0,x_test0,y_train0,y_test0 = train_test_split(data0,y0, test_size = 0.1)\n",
        "      x_train1,x_test1,y_train1,y_test1 = train_test_split(data1,y1, test_size = 0.1)\n",
        "      \n",
        "      x_train = np.concatenate((x_train0,x_train1))\n",
        "      y_train = np.concatenate((y_train0,y_train1))\n",
        "      x_test = np.concatenate((x_test0,x_test1))\n",
        "      y_test = np.concatenate((y_test0,y_test1))\n",
        "      \n",
        "      x_train,y_train = shuffle(x_train,y_train)\n",
        "      x_test,y_test = shuffle(x_test,y_test)\n",
        "    \n",
        "    return x_train,y_train,x_test,y_test\n",
        "\n",
        "def pcaPlot(X, y, descr= 'temporel',plot_samples = 500):\n",
        "  '''\n",
        "  Defines and 10 components PCA of the dataset X and plots the first 3\n",
        "  '''\n",
        "  pca = PCA(n_components=10)\n",
        "  x_PCA = pca.fit_transform(X)\n",
        "\n",
        "  # let's visualize the data in 3d\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(111, projection='3d')\n",
        "  ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
        "  ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
        "  ax.set_zlabel('Principal Component 3', fontsize = 15)\n",
        "  ax.set_title('ACP du signal ' + descr, fontsize = 20)\n",
        "  targets = [0,1]\n",
        "  colors = ['b', 'r']\n",
        "  x_PCA_plot = x_PCA[0:plot_samples]\n",
        "\n",
        "  for target, color in zip(targets,colors):\n",
        "      indexes = np.where(y[0:plot_samples] == target)\n",
        "      ax.scatter(x_PCA_plot[indexes,0]\n",
        "                , x_PCA_plot[indexes,1],\n",
        "                x_PCA_plot[indexes,2]\n",
        "                , c = color\n",
        "                , s = 50)\n",
        "  ax.legend(['pas d\\'exoplanetes', 'exoplanetes'])\n",
        "  ax.grid()\n",
        "  plt.show()\n",
        "  return None\n",
        "\n",
        "#Make an identity sampler\n",
        "class FakeSampler(BaseSampler):\n",
        "\n",
        "    _sampling_type = 'bypass'\n",
        "\n",
        "    def _fit_resample(self, X, y):\n",
        "        return X, y\n",
        "\n",
        "def plot_resampling(X, y, sampling, ax):\n",
        "    X_res, y_res = sampling.fit_resample(X, y)\n",
        "    ax.scatter(X_res[:, 0], X_res[:, 1], c=y_res, alpha=0.8, edgecolor='k')\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.get_xaxis().tick_bottom()\n",
        "    ax.get_yaxis().tick_left()\n",
        "    ax.spines['left'].set_position(('outward', 10))\n",
        "    ax.spines['bottom'].set_position(('outward', 10))\n",
        "    return Counter(y_res)\n",
        "\n",
        "def SMOTE_plot(x_train, y_train):\n",
        "  sampler = FakeSampler()\n",
        "\n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 15))\n",
        "  plot_resampling(x_train, y_train, sampler, ax1)\n",
        "  ax1.set_title('Original data - y={}'.format(Counter(y_train)))\n",
        "\n",
        "  plot_resampling(x_train, y_train, SMOTE(random_state = 0), ax2)\n",
        "  ax2.set_title('Resampling using {}'.format(SMOTE(random_state=0).__class__.__name__))\n",
        "  fig.tight_layout()\n",
        "  plt.show()\n",
        "  return None\n",
        "\n",
        "def transform_dataset(X, mode='wavelet', wname='db5',nsamples=10):\n",
        "  if mode == 'wavelet':\n",
        "    return pywt.dwt(X, wname)[0][:,0:nsamples]\n",
        "\n",
        "  elif mode == 'fft':\n",
        "    return np.abs(np.fft.fft(X))[:,0:nsamples]\n",
        "\n",
        "  elif mode == 'all_in':\n",
        "    allz = np.abs(np.fft.fft(X))[:,0:nsamples]\n",
        "    wnames = ['db5','sym5','coif5','bior2.4']\n",
        "    for wn in wnames:\n",
        "      np.append(allz, pywt.dwt(X, wn)[0][:,0:nsamples], axis=1)\n",
        "    return allz\n",
        "\n",
        "def scale_datasets(X_train, X_test, param='standardScaling', reshape=True):\n",
        "  SC = StandardScaler()\n",
        "  train_shape = X_train.shape\n",
        "  test_shape = X_test.shape\n",
        "    \n",
        "  if param == 'standardScaling':\n",
        "    SC.fit(X_train)\n",
        "    if reshape:\n",
        "      return SC.transform(X_train).reshape(train_shape[0],train_shape[1],1), SC.transform(X_test).reshape(test_shape[0],test_shape[1],1)\n",
        "    else :\n",
        "      return SC.transform(X_train), SC.transform(X_test)\n",
        "\n",
        "  elif param == 'RPN':\n",
        "    \n",
        "    mean_train = np.mean(X_train,axis=1).reshape(X_train.shape[0],1)\n",
        "    mean_test = np.mean(X_test,axis=1).reshape(X_test.shape[0],1)\n",
        "    \n",
        "    norm_train = np.max(np.abs(X_train),axis=1).reshape(-1,1)#np.linalg.norm(X_train,axis=1).reshape(-1,1)\n",
        "    norm_test = np.max(np.abs(X_test),axis=1).reshape(-1,1)#np.linalg.norm(X_test,axis=1).reshape(-1,1)\n",
        "    \n",
        "    if reshape:\n",
        "      return ((X_train-mean_train)/norm_train) .reshape(train_shape[0],train_shape[1],1) , ((X_test-mean_test)/norm_test) .reshape(test_shape[0],test_shape[1],1)\n",
        "    else :\n",
        "      return ((X_train-mean_train)/norm_train)  , ((X_test-mean_test)/norm_test) \n",
        "    \n",
        "    \n",
        "  elif param == 'transpose':\n",
        "    X_train = np.transpose(X_train)\n",
        "    if train_shape != test_shape :\n",
        "      X_test = np.tile(X_test,(10,1))[0:train_shape[0]]\n",
        "    X_test = np.transpose(X_test)\n",
        "    SC.fit(X_train)\n",
        "    if reshape:\n",
        "      return np.transpose(SC.transform(X_train)).reshape(train_shape[0],train_shape[1],1), np.transpose(SC.transform(X_test))[0:test_shape[0]].reshape(test_shape[0],test_shape[1],1)\n",
        "    else :\n",
        "      return np.transpose(SC.transform(X_train)), np.transpose(SC.transform(X_test))[0:test_shape[0]]\n",
        "    \n",
        "  elif param == 'flatten':\n",
        "    X_train = X_train.flatten().reshape((-1,1))\n",
        "    X_test = X_test.flatten().reshape((-1,1))\n",
        "    SC.fit(X_train)\n",
        "    if reshape:\n",
        "      return SC.transform(X_train).reshape(train_shape[0],train_shape[1],1), SC.transform(X_test).reshape(test_shape[0],test_shape[1],1)\n",
        "    else :\n",
        "      return SC.transform(X_train).reshape(train_shape[0],train_shape[1]), SC.transform(X_test).reshape(test_shape[0],test_shape[1])\n",
        "  \n",
        "  elif param == 'norm':\n",
        "    norm_train = np.linalg.norm(X_train,axis=1).reshape(-1,1)\n",
        "    norm_test = np.linalg.norm(X_test,axis=1).reshape(-1,1)\n",
        "    if reshape:\n",
        "      return (X_train/norm_train).reshape(train_shape[0],train_shape[1],1), (X_test/norm_test).reshape(test_shape[0],test_shape[1],1)\n",
        "    else :\n",
        "      return X_train/norm_train, X_test/norm_test\n",
        "    \n",
        "  elif param == 'norm_flatten':\n",
        "    norm_train = np.linalg.norm(X_train)\n",
        "    norm_test = np.linalg.norm(X_test,axis=1).reshape(-1,1)\n",
        "    if reshape:\n",
        "      return (X_train/norm_train).reshape(train_shape[0],train_shape[1],1), (X_test/norm_train).reshape(test_shape[0],test_shape[1],1)\n",
        "    else :\n",
        "      return X_train/norm_train, X_test/norm_train\n",
        "\n",
        "def inv_data(X, y):\n",
        "  X_flipped = np.flip(X[np.where(y == 1)[0]], 1)\n",
        "  y_flipped = np.ones((X_flipped.shape[0]))\n",
        "  return np.concatenate((X, X_flipped)), np.concatenate((y, y_flipped))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBXv4ImW_60C",
        "colab_type": "text"
      },
      "source": [
        "# METRICS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YALCfl9M_-KW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getScores_cross(pred, result, display=False):\n",
        "  confusion = confusion_matrix(result, pred)\n",
        "  \n",
        "  if display:\n",
        "    print('Precision :')\n",
        "    print(precision_score(result, pred))\n",
        "    print('Recall :')\n",
        "    print(recall_score(result, pred))\n",
        "    print('F1 Score :')\n",
        "    print(f1_score(result, pred))\n",
        "    print('MSE :')\n",
        "    print('')\n",
        "    print(mean_squared_error(result, pred))\n",
        "    print('confusion_matrix : ')\n",
        "    print(confusion)\n",
        "    print('')\n",
        "  \n",
        "  return confusion \n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "  \"\"\"Recall metric.\n",
        "  Only computes a batch-wise average of recall.\n",
        "  Computes the recall, a metric for multi-label classification of\n",
        "  how many relevant items are selected.\n",
        "  \"\"\"\n",
        "  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "  possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "  return true_positives / (possible_positives + K.epsilon())\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "  \"\"\"Precision metric.\n",
        "  Only computes a batch-wise average of precision.\n",
        "  Computes the precision, a metric for multi-label classification of\n",
        "  how many selected items are relevant.\n",
        "  \"\"\"\n",
        "  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "  predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "  return true_positives / (predicted_positives + K.epsilon())\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "  preci = precision(y_true, y_pred)\n",
        "  rec = recall(y_true, y_pred)\n",
        "  return 2*((preci*rec)/(preci+rec+K.epsilon()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl4HT84oAOgo",
        "colab_type": "text"
      },
      "source": [
        "# NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQiMkUnUAQK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def maxinet(x_train,y_train,x_test,y_test):\n",
        "  #X = X.reshape(-1,1)\n",
        "  #X_tst = X_tst.reshape(-1,1)\n",
        "  model = Sequential()\n",
        "\n",
        "  \n",
        "  model.add(Conv1D(16, 200, activation='relu', padding='same', input_shape=x_train.shape[1:]))\n",
        "  model.add(MaxPooling1D(4, padding='same'))\n",
        "  model.add(Conv1D(8, 100, activation='relu', padding='same'))\n",
        "  model.add(MaxPooling1D(4, padding='same'))\n",
        "  model.add(Conv1D(4, 10, activation='relu', padding='same'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(CuDNNLSTM(200, return_sequences=True))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(CuDNNLSTM(20)) \n",
        "  #model.add(CuDNNLSTM(70, return_sequences=True))\n",
        "  model.add(Dropout(0.2))\n",
        "  #model.add(CuDNNLSTM(10))\n",
        "  #model.add(Dropout(0.2))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  \n",
        "  '''\n",
        "  autoencoder.add(UpSampling1D(4))\n",
        "  autoencoder.add(Conv1D(1, 4, activation='sigmoid', padding='same'))\n",
        "  '''\n",
        "  model.summary()\n",
        "\n",
        "\n",
        "\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy',metrics=[precision]) #[f1, precision, \"accuracy\"]\n",
        "  model.fit(x_train, y_train,\n",
        "                  epochs=6,\n",
        "                  shuffle = True,\n",
        "                  batch_size=32)\n",
        "  \n",
        "\n",
        "\n",
        "  return model, np.rint(model.predict(x_test))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ml5ft1czAcVD",
        "colab_type": "text"
      },
      "source": [
        "# TESTING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D83iTNYAAobP",
        "colab_type": "text"
      },
      "source": [
        "## Data load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hI6h7wmAeRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train, x_test, y_test = dataload(merge=True,path='drive/My Drive/M1/IA/')\n",
        "\n",
        "x_train, y_train = bootstrap(x_train, y_train)\n",
        "x_test, y_test = bootstrap(x_test, y_test,inv=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha_DNHRlBzFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test = scale_datasets(x_train, x_test, param='RPN')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKm3U3odhBFJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1fdf0717-51f3-4750-aeef-10b825732bb9"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10106, 3197, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c23oHduTRNhA",
        "colab_type": "text"
      },
      "source": [
        "## Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsYRsmC4Z33p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def maxinet_cross(x_train,y_train,x_test,y_test, tst=False):\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv1D(16, 200, activation='relu', padding='same', input_shape=x_train.shape[1:]))\n",
        "  model.add(MaxPooling1D(4, padding='same'))\n",
        "  model.add(Conv1D(8, 100, activation='relu', padding='same'))\n",
        "  model.add(MaxPooling1D(4, padding='same'))\n",
        "  model.add(Conv1D(4, 10, activation='relu', padding='same'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(CuDNNLSTM(200, return_sequences=True))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(CuDNNLSTM(20)) \n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy',metrics=[precision]) #[f1, precision, \"accuracy\"]\n",
        "  if tst:\n",
        "    model.fit(x_train, y_train,\n",
        "                    epochs=1,\n",
        "                    shuffle = True,\n",
        "                    batch_size=128)\n",
        "  else:\n",
        "    model.fit(x_train, y_train,\n",
        "                    epochs=6,\n",
        "                    shuffle = True,\n",
        "                    batch_size=32)\n",
        "  \n",
        "\n",
        "  return np.rint(model.predict(x_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbDeUS9lRo66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cross_validation(X, y, splits=5, testing=False): #PBL maybe because of bootstrap maybe do boostrap in here because we could have 30 times one exo in val data...\n",
        "  #We first need to split the train set into exoplanet and non-exoplanet so that there isn't any expolanet in either the train or val test for example\n",
        "  x_stars = X[np.where(y==0)]\n",
        "  y_stars = y[np.where(y==0)]\n",
        "  x_exo = X[np.where(y==1)]\n",
        "  y_exo = y[np.where(y==1)]\n",
        "\n",
        "  kf = KFold(n_splits=splits, random_state=None, shuffle=False)\n",
        "  \n",
        "  split_stars = kf.split(x_stars)\n",
        "  split_exo = kf.split(x_exo)\n",
        "  scores = np.zeros((splits, 2, 2))\n",
        "\n",
        "  for k in range(splits):\n",
        "    spS = next(split_stars)\n",
        "    spE = next(split_exo)\n",
        "    idx_tra_S = spS[0]\n",
        "    idx_val_S = spS[1]\n",
        "    idx_tra_E = spE[0]\n",
        "    idx_val_E = spE[1]\n",
        "\n",
        "    x_tra = np.concatenate((x_stars[idx_tra_S], x_exo[idx_tra_E]))\n",
        "    y_tra = np.concatenate((y_stars[idx_tra_S], y_exo[idx_tra_E]))\n",
        "    x_val = np.concatenate((x_stars[idx_val_S], x_exo[idx_val_E]))\n",
        "    y_val = np.concatenate((y_stars[idx_val_S], y_exo[idx_val_E]))\n",
        "    x_tra, y_tra = shuffle(x_tra, y_tra)\n",
        "    x_val, y_val = shuffle(x_val, y_val)\n",
        "    pred = maxinet_cross(x_tra, y_tra, x_val, y_val, tst=testing)\n",
        "    scores[k] = getScores_cross(y_val, pred)\n",
        "\n",
        "  return scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki7Gd63Hbz-o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dee08bc4-909a-40c0-8633-44defc51a390"
      },
      "source": [
        "Scores = cross_validation(x_train, y_train, 5)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_4 (Conv1D)            (None, 3197, 16)          3216      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 800, 16)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 800, 8)            12808     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 200, 8)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 200, 4)            324       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 200, 4)            0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_3 (CuDNNLSTM)     (None, 200, 200)          164800    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 200, 200)          0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_4 (CuDNNLSTM)     (None, 20)                17760     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 198,929\n",
            "Trainable params: 198,929\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/6\n",
            "8084/8084 [==============================] - 22s 3ms/step - loss: 0.6731 - precision: 0.5781\n",
            "Epoch 2/6\n",
            "8084/8084 [==============================] - 20s 2ms/step - loss: 0.6521 - precision: 0.6654\n",
            "Epoch 3/6\n",
            "8084/8084 [==============================] - 20s 2ms/step - loss: 0.3821 - precision: 0.8564\n",
            "Epoch 4/6\n",
            "8084/8084 [==============================] - 20s 2ms/step - loss: 0.2209 - precision: 0.9201\n",
            "Epoch 5/6\n",
            "8084/8084 [==============================] - 20s 2ms/step - loss: 0.1393 - precision: 0.9468\n",
            "Epoch 6/6\n",
            "8084/8084 [==============================] - 20s 2ms/step - loss: 0.1217 - precision: 0.9509\n",
            "Precision :\n",
            "1.0\n",
            "Recall :\n",
            "0.9335180055401662\n",
            "F1 Score :\n",
            "0.9656160458452722\n",
            "MSE :\n",
            "0.03560830860534125\n",
            "\n",
            "confusion_matrix : \n",
            "[[ 939    0]\n",
            " [  72 1011]]\n",
            "\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_7 (Conv1D)            (None, 3197, 16)          3216      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 800, 16)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 800, 8)            12808     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1 (None, 200, 8)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_9 (Conv1D)            (None, 200, 4)            324       \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 200, 4)            0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_5 (CuDNNLSTM)     (None, 200, 200)          164800    \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 200, 200)          0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_6 (CuDNNLSTM)     (None, 20)                17760     \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 198,929\n",
            "Trainable params: 198,929\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/6\n",
            "8084/8084 [==============================] - 23s 3ms/step - loss: 0.5259 - precision: 0.7459\n",
            "Epoch 2/6\n",
            "8084/8084 [==============================] - 22s 3ms/step - loss: 0.3303 - precision: 0.8366\n",
            "Epoch 3/6\n",
            "8084/8084 [==============================] - 21s 3ms/step - loss: 0.3232 - precision: 0.8609\n",
            "Epoch 4/6\n",
            "8084/8084 [==============================] - 20s 3ms/step - loss: 0.1604 - precision: 0.9344\n",
            "Epoch 5/6\n",
            "8084/8084 [==============================] - 20s 3ms/step - loss: 0.2661 - precision: 0.9150\n",
            "Epoch 6/6\n",
            "8084/8084 [==============================] - 20s 3ms/step - loss: 0.1854 - precision: 0.9216\n",
            "Precision :\n",
            "1.0\n",
            "Recall :\n",
            "0.9674641148325359\n",
            "F1 Score :\n",
            "0.9834630350194552\n",
            "MSE :\n",
            "0.016815034619188922\n",
            "\n",
            "confusion_matrix : \n",
            "[[ 977    0]\n",
            " [  34 1011]]\n",
            "\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_10 (Conv1D)           (None, 3197, 16)          3216      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1 (None, 800, 16)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_11 (Conv1D)           (None, 800, 8)            12808     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_8 (MaxPooling1 (None, 200, 8)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_12 (Conv1D)           (None, 200, 4)            324       \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 200, 4)            0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_7 (CuDNNLSTM)     (None, 200, 200)          164800    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 200, 200)          0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_8 (CuDNNLSTM)     (None, 20)                17760     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 198,929\n",
            "Trainable params: 198,929\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/6\n",
            "8084/8084 [==============================] - 23s 3ms/step - loss: 0.6738 - precision: 0.5641\n",
            "Epoch 2/6\n",
            "8084/8084 [==============================] - 20s 3ms/step - loss: 0.6413 - precision: 0.6090\n",
            "Epoch 3/6\n",
            "8084/8084 [==============================] - 20s 3ms/step - loss: 0.4031 - precision: 0.8243\n",
            "Epoch 4/6\n",
            "8084/8084 [==============================] - 20s 3ms/step - loss: 0.3693 - precision: 0.8487\n",
            "Epoch 5/6\n",
            "8084/8084 [==============================] - 20s 2ms/step - loss: 0.2034 - precision: 0.9150\n",
            "Epoch 6/6\n",
            "8084/8084 [==============================] - 20s 2ms/step - loss: 0.1416 - precision: 0.9449\n",
            "Precision :\n",
            "0.9772502472799208\n",
            "Recall :\n",
            "0.9686274509803922\n",
            "F1 Score :\n",
            "0.9729197439684883\n",
            "MSE :\n",
            "0.027200791295746787\n",
            "\n",
            "confusion_matrix : \n",
            "[[979  23]\n",
            " [ 32 988]]\n",
            "\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_13 (Conv1D)           (None, 3197, 16)          3216      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_9 (MaxPooling1 (None, 800, 16)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_14 (Conv1D)           (None, 800, 8)            12808     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_10 (MaxPooling (None, 200, 8)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_15 (Conv1D)           (None, 200, 4)            324       \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 200, 4)            0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_9 (CuDNNLSTM)     (None, 200, 200)          164800    \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 200, 200)          0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_10 (CuDNNLSTM)    (None, 20)                17760     \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 198,929\n",
            "Trainable params: 198,929\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/6\n",
            "8086/8086 [==============================] - 24s 3ms/step - loss: 0.5492 - precision: 0.7087\n",
            "Epoch 2/6\n",
            "8086/8086 [==============================] - 20s 2ms/step - loss: 0.2521 - precision: 0.8777\n",
            "Epoch 3/6\n",
            "8086/8086 [==============================] - 20s 2ms/step - loss: 0.1609 - precision: 0.9229\n",
            "Epoch 4/6\n",
            "8086/8086 [==============================] - 20s 2ms/step - loss: 0.1430 - precision: 0.9405\n",
            "Epoch 5/6\n",
            "8086/8086 [==============================] - 20s 2ms/step - loss: 0.1503 - precision: 0.9428\n",
            "Epoch 6/6\n",
            "8086/8086 [==============================] - 20s 2ms/step - loss: 0.1157 - precision: 0.9483\n",
            "Precision :\n",
            "1.0\n",
            "Recall :\n",
            "0.9430438842203548\n",
            "F1 Score :\n",
            "0.9706871696299856\n",
            "MSE :\n",
            "0.030198019801980197\n",
            "\n",
            "confusion_matrix : \n",
            "[[ 949    0]\n",
            " [  61 1010]]\n",
            "\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_16 (Conv1D)           (None, 3197, 16)          3216      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_11 (MaxPooling (None, 800, 16)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_17 (Conv1D)           (None, 800, 8)            12808     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_12 (MaxPooling (None, 200, 8)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_18 (Conv1D)           (None, 200, 4)            324       \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 200, 4)            0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_11 (CuDNNLSTM)    (None, 200, 200)          164800    \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 200, 200)          0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_12 (CuDNNLSTM)    (None, 20)                17760     \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 198,929\n",
            "Trainable params: 198,929\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/6\n",
            "8086/8086 [==============================] - 24s 3ms/step - loss: 0.6043 - precision: 0.7184\n",
            "Epoch 2/6\n",
            "8086/8086 [==============================] - 20s 3ms/step - loss: 0.4201 - precision: 0.8232\n",
            "Epoch 3/6\n",
            "8086/8086 [==============================] - 20s 2ms/step - loss: 0.6499 - precision: 0.6312\n",
            "Epoch 4/6\n",
            "8086/8086 [==============================] - 20s 2ms/step - loss: 0.6058 - precision: 0.6672\n",
            "Epoch 5/6\n",
            "8086/8086 [==============================] - 20s 2ms/step - loss: 0.5622 - precision: 0.6912\n",
            "Epoch 6/6\n",
            "8086/8086 [==============================] - 20s 2ms/step - loss: 0.3620 - precision: 0.8281\n",
            "Precision :\n",
            "0.9752475247524752\n",
            "Recall :\n",
            "0.9363117870722434\n",
            "F1 Score :\n",
            "0.9553831231813774\n",
            "MSE :\n",
            "0.04554455445544554\n",
            "\n",
            "confusion_matrix : \n",
            "[[943  25]\n",
            " [ 67 985]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdRezmdcmVWF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "fae5bd8b-c3ad-4a89-f4fa-0301a09e79d1"
      },
      "source": [
        "print(Scores)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[ 939.    0.]\n",
            "  [  72. 1011.]]\n",
            "\n",
            " [[ 977.    0.]\n",
            "  [  34. 1011.]]\n",
            "\n",
            " [[ 979.   23.]\n",
            "  [  32.  988.]]\n",
            "\n",
            " [[ 949.    0.]\n",
            "  [  61. 1010.]]\n",
            "\n",
            " [[ 943.   25.]\n",
            "  [  67.  985.]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mtpQGQQIrX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}